{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# settings\n",
    "train_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "mat_contents = sio.loadmat('dataset.mat')\n",
    "signal_absent = mat_contents['signal_absent']\n",
    "signal_present = mat_contents['signal_present']\n",
    "\n",
    "# format data for tensorflow\n",
    "signal_absent = np.swapaxes(signal_absent,1,2)\n",
    "signal_absent = np.swapaxes(signal_absent,0,1)\n",
    "signal_present = np.swapaxes(signal_present,1,2)\n",
    "signal_present = np.swapaxes(signal_present,0,1)\n",
    "\n",
    "# split the dataset into train,validation\n",
    "signal_absent_train = signal_absent[0:train_size,:,:]\n",
    "signal_present_train = signal_present[0:train_size,:,:]\n",
    "signal_absent_val = signal_absent[train_size:200,:,:,]\n",
    "signal_present_val = signal_present[train_size:200,:,:]\n",
    "\n",
    "# now combine the positive/negative examples into one array\n",
    "train_set = np.concatenate((signal_absent_train,signal_present_train),axis=0)\n",
    "val_set = np.concatenate((signal_absent_val,signal_present_val),axis=0)\n",
    "\n",
    "# now convert the sets to a tensor and reshape for features layer\n",
    "train_set = np.reshape(train_set,(-1,64,64,1))\n",
    "val_set = np.reshape(val_set,(-1,64,64,1))\n",
    "\n",
    "# create labels for training and validation set\n",
    "labels_train = tf.concat([\n",
    "        tf.zeros(signal_absent_train.shape[0],dtype=tf.float64),\n",
    "        tf.ones(signal_present_train.shape[0],dtype=tf.float64)\n",
    "    ],axis=0)\n",
    "labels_val = tf.concat([\n",
    "        tf.zeros(signal_absent_val.shape[0],dtype=tf.float64),\n",
    "        tf.ones(signal_present_val.shape[0],dtype=tf.float64)\n",
    "    ],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup placeholder for network input\n",
    "net_input = tf.placeholder(tf.float64,shape=[None,64,64,1])\n",
    "\n",
    "# setup layers\n",
    "conv0 = tf.layers.conv2d(inputs=net_input,filters=32,kernel_size=(5,5),padding='same',activation=tf.nn.relu,name='conv0')\n",
    "pool0 = tf.layers.max_pooling2d(inputs=conv0,pool_size=(2,2),strides=2,name='pool0')\n",
    "dense0 = tf.layers.dense(inputs=tf.reshape(pool0,[-1,pool0.shape[1]*pool0.shape[2]*32]),units=128,activation=tf.nn.relu,name='dense0')\n",
    "readout = tf.squeeze(tf.layers.dense(inputs=dense0,units=1))\n",
    "\n",
    "# set loss function\n",
    "loss = tf.losses.sigmoid_cross_entropy(readout,labels_train)\n",
    "loss_summary = tf.summary.scalar('loss',loss)\n",
    "\n",
    "# setup optimizer\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# check accuracy on training set\n",
    "training_accuracy,ta_op = tf.metrics.accuracy(labels_train,tf.sigmoid(readout))\n",
    "train_summary = tf.summary.scalar('training_accuracy',training_accuracy)\n",
    "\n",
    "# check AUC on validation set\n",
    "AUC,AUC_op = tf.metrics.auc(labels_val,tf.sigmoid(readout))\n",
    "AUC_summary = tf.summary.scalar('AUC',AUC)\n",
    "\n",
    "# create summary op\n",
    "summary_op = tf.summary.merge([loss_summary,train_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup and run tensorflow session\n",
    "with tf.Session() as sess:\n",
    "    # initialize all variables\n",
    "    sess.run([tf.global_variables_initializer(),tf.local_variables_initializer()])\n",
    "    writer = tf.summary.FileWriter('./logdir',sess.graph)\n",
    "    for i in range(100):\n",
    "        summary,_,_ = sess.run([summary_op, ta_op, train_op], feed_dict={net_input: train_set})\n",
    "        writer.add_summary(summary,i)\n",
    "        AUC_summary_out,_ = sess.run([AUC_summary, AUC_op], feed_dict={net_input: val_set})\n",
    "        writer.add_summary(AUC_summary_out,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
